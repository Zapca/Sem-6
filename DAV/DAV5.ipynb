{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as mtp \n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss , acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as best_arima_finder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"AAPL.csv\")\n",
    "data2 = pd.read_csv(\"AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Date' , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Augmented Dickey-Fuller Test (ADF)\n",
    "\n",
    "**The Augmented Dickey-Fuller Test (ADF)** is a unit root test commonly used to determine the stationarity of time series data. It is an extension of the original Dickey-Fuller test and is more powerful, capable of handling more complex models.\n",
    "\n",
    "### Hypotheses:\n",
    "- **Null Hypothesis (H0)**: The time series data is non-stationary.\n",
    "- **Alternate Hypothesis (H1)**: The time series is stationary (or trend-stationary).\n",
    "\n",
    "### **Test Procedure:**\n",
    "The ADF test extends the Dickey-Fuller test equation by including a Close order regressive process in the model. This increases the thoroughness of the test while keeping the null hypothesis unchanged.\n",
    "\n",
    "### **Interpretation:**\n",
    "To reject the null hypothesis and conclude that the series is stationary, the p-value produced by the test should be less than the significance level (e.g., 0.05).\n",
    "\n",
    "# Kwiatkowski Phillips Schmidt Shin (KPSS) Test\n",
    "\n",
    "The Kwiatkowski Phillips Schmidt Shin (KPSS) test is another method used to determine the stationarity of time series data, specifically around a mean or linear trend.\n",
    "\n",
    "## Hypotheses:\n",
    "- **Null Hypothesis (H0):** The data is stationary.\n",
    "- **Alternate Hypothesis (H1):** The data is not stationary.\n",
    "\n",
    "### Test Procedure:\n",
    "\n",
    "The KPSS test utilizes linear regression to divide a series into three components: a deterministic trend, a random walk, and a stationary error. It employs Ordinary Least Squares (OLS) regression to compute the equation.\n",
    "\n",
    "### Interpretation:\n",
    "For level stationarity, the intercept will have a fixed element, or the series will be stationary around a fixed level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data2[['Date', 'Close']].copy()\n",
    "data_test.set_index('Date' , inplace=True)\n",
    "data_test[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=mtp.figure(figsize=(15,6))\n",
    "sns.lineplot(data=data_test,x='Date',y='Close')\n",
    "mtp.tick_params(\n",
    "    axis='x',        \n",
    "    which='both',   \n",
    "    bottom=False,      \n",
    "    top=False,        \n",
    "    labelbottom=False) \n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = adfuller(data_test['Close'])\n",
    "kps = kpss(data_test['Close'] , regression = \"ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Statistic \" , adf[0])\n",
    "print(\"p-value \" , adf[1])\n",
    "print(\"Critical Values\")\n",
    "for i,j in adf[4].items():\n",
    "    print('\\t%s: %.3f' %(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the test statistic is greater than the critical value we accept the null hypotheses . the data is non stationary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Statistic \" , kps[0])\n",
    "print(\"p-value \" , kps[1])\n",
    "print(\"Critical Values\")\n",
    "for i,j in kps[3].items():\n",
    "    print('\\t%s: %.3f' %(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the test statistics value is greater than the critical value, the null hypothesis is rejected. This indicates that the data is non-stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationarising the non stationary data \n",
    "# we can do that by following methods \n",
    "# 1. Log transformation \n",
    "# 2. Square Root \n",
    "# 3. Cube Root \n",
    "# for this we will use the second method \n",
    "\n",
    "data_test_sqrt = np.sqrt(data_test['Close'])\n",
    "data_test_diff = data_test_sqrt.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now applying the tests again to the\n",
    "# square_rooted data to check the stationarity of the dataset\n",
    "adf2 = adfuller(data_test_diff)\n",
    "kps2 = kpss(data_test_diff , regression=\"ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Statistic \" , adf2[0])\n",
    "print(\"p-value \" , adf2[1])\n",
    "print(\"Critical Values\")\n",
    "for i,j in adf2[4].items():\n",
    "    print('\\t%s: %.3f' %(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the ADF test statics is lesser (more negative) then the critical value becomes the reason to reject the null hypothesis. This indicates that the data is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Statistic \" , kps2[0])\n",
    "print(\"p-value \" , kps2[1])\n",
    "print(\"Critical Values\")\n",
    "for i,j in kps2[3].items():\n",
    "    print('\\t%s: %.3f' %(i, j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the KPSS test statistics value is less than the critical value, the null hypothesis is not rejected. This indicates that the data is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp.figure(figsize=(15,8))\n",
    "mtp.plot(data_test_diff,label=\"after\")\n",
    "mtp.plot(data_test['Close'],label=\"before\")\n",
    "mtp.tick_params(\n",
    "    axis='x',        \n",
    "    which='both',   \n",
    "    bottom=False,      \n",
    "    top=False,        \n",
    "    labelbottom=False)\n",
    "mtp.legend()\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the Before line shows an increasing value of the Close stock per time wherase the After line shows a stationary value over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp.plot(data_test_diff,label=\"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "\n",
    "# Original Series\n",
    "fig, axes = mtp.subplots(3, 2, sharex=True)\n",
    "axes[0, 0].plot(data_test['Close']); axes[0, 0].set_title('Original Series')\n",
    "plot_acf(data_test['Close'], ax=axes[0, 1])\n",
    "\n",
    "# 1st Differencing\n",
    "axes[1, 0].plot(data_test_diff); axes[1, 0].set_title('1st Order Differencing')\n",
    "plot_acf(data_test_diff, ax=axes[1, 1])\n",
    "\n",
    "# 2nd Differencing\n",
    "axes[2, 0].plot(data_test_sqrt.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\n",
    "plot_acf(data_test_sqrt.diff().diff().dropna(), ax=axes[2, 1])\n",
    "\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. This way, we will know if that lag is needed in the AR term or not.\n",
    "\n",
    "ùëåùë°=ùõº0+ùõº1ùëåùë°‚àí1+ùõº2ùëåùë°‚àí2+ùõº3ùëåùë°‚àí3\n",
    "\n",
    "That is, suppose, if Y_t is the current series and Y_t-1 is the lag 1 of Y, then the partial autocorrelation of lag 3 (Y_t-3) is the coefficient  ùõº3  of Y_t-3 in the above equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtp.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n",
    "\n",
    "fig, axes = mtp.subplots(1, 2, sharex=True)\n",
    "axes[0].plot(data_test_diff); axes[0].set_title('1st Differencing')\n",
    "axes[1].set(ylim=(0,5))\n",
    "plot_pacf(data_test_diff, ax=axes[1])\n",
    "\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Partical Auto-Correlation Lag is quite significant so we will take \n",
    "**p = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ACF tells how many MA terms are \n",
    "# required to remove any autocorrelation\n",
    "# in the stationarized series.\n",
    "# Therefore we will take the acf of the firt order differenciartion to find the q \n",
    "\n",
    "mtp.rcParams.update({'figure.figsize':(9,3), 'figure.dpi':120})\n",
    "\n",
    "fig, axes = mtp.subplots(1, 2, sharex=True)\n",
    "axes[0].plot(data_test_diff); axes[0].set_title('1st Differencing')\n",
    "axes[1].set(ylim=(0,4))\n",
    "plot_acf(data_test_diff, ax=axes[1])\n",
    "\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see only one lag above yhe significant line we take 1 as q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there fore building ARIMA 1,1,1 Model\n",
    "\n",
    "model = ARIMA(data_test['Close'] , order = (1,1,1))\n",
    "model_fit = model.fit()\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Residual Errors \n",
    "\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "fig, ax = mtp.subplots(1,2)\n",
    "residuals.plot(title=\"Residuals\", ax=ax[0])\n",
    "residuals.plot(kind='kde', title='Density', ax=ax[1])\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THe Density of is very fine with a mean of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model_fit.forecast(steps=10)  # Adjust the number of steps as needed\n",
    "mtp.plot(forecast, label='Forecast')\n",
    "mtp.legend()\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_test.values[:8374]\n",
    "test = data_test.values[8374:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train, order=(1, 1, 1))  \n",
    "fitted = model.fit()  \n",
    "\n",
    "forecast_results = fitted.get_forecast(steps=2094, alpha=0.05)  # 95% confidence interval\n",
    "\n",
    "# Extract forecasted values, standard errors, and confidence intervals\n",
    "fc = forecast_results.predicted_mean\n",
    "se = forecast_results.se_mean\n",
    "conf = forecast_results.conf_int()\n",
    "\n",
    "# Make as pandas series\n",
    "fc_series = pd.Series(fc)\n",
    "lower_series = pd.Series(conf[:, 0])\n",
    "upper_series = pd.Series(conf[:, 1])\n",
    "\n",
    "# Plot\n",
    "mtp.figure(figsize=(12,5), dpi=100)\n",
    "mtp.plot(train, label='training')\n",
    "mtp.plot(test, label='actual')\n",
    "mtp.plot(fc_series, label='forecast')\n",
    "mtp.fill_between(lower_series.index, lower_series, upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "mtp.title('Forecast vs Actuals')\n",
    "mtp.legend(loc='upper left', fontsize=8)\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error , mean_absolute_error ,mean_squared_error\n",
    "\n",
    "def forecast_accuracy(forecast, actual):\n",
    "    forecast = np.squeeze(forecast)  # Remove single-dimensional entries from the shape of an array\n",
    "    actual = np.squeeze(actual)\n",
    "    mape = mean_absolute_percentage_error(actual , forecast)\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = mean_absolute_error(actual,forecast)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, forecast))\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    mse = mean_squared_error(actual , forecast)\n",
    "    return({'mape':mape, 'me':me, 'mae': mae, \n",
    "            'mpe': mpe, 'rmse':rmse, 'mse' : mse } )\n",
    "\n",
    "forecast_accuracy(fc, test)\n",
    "\n",
    "# Assuming fc and test are arrays containing the forecasted and actual values respectively\n",
    "metrics = forecast_accuracy(fc, test)\n",
    "\n",
    "# Print the metrics\n",
    "for key, value in metrics.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 55.72% MAPE implies the model is about 44.23% accurate in predicting the next 2094 observations. Now we know how to build an ARIMA model manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pmdarima for finding the best arima modeL\n",
    "model_2 = best_arima_finder.auto_arima(\n",
    "    data_test.values , \n",
    "    start_p= 1 , \n",
    "    start_q = 1 , \n",
    "    test= \"kpss\" , \n",
    "    max_p=3,\n",
    "    max_q=3,\n",
    "    d = None , \n",
    "    trace = True , \n",
    "    seasonal= False , \n",
    "    error_action= \"ignore\" , \n",
    "    suppress_warnings= True , \n",
    "    stepwise= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as per the autoarima function we get p as 3 , q as 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.plot_diagnostics(figsize=(10,8))\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_periods = 24\n",
    "fc, confint = model_2.predict(n_periods=n_periods, return_conf_int=True)\n",
    "index_of_fc = np.arange(len(data_test.values), len(data_test.values)+n_periods)\n",
    "\n",
    "# make series for plotting purpose\n",
    "fc_series = pd.Series(fc, index=index_of_fc)\n",
    "lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
    "upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
    "\n",
    "# Plot\n",
    "mtp.plot(data_test.values)\n",
    "mtp.plot(fc_series, color='darkgreen')\n",
    "mtp.fill_between(lower_series.index, \n",
    "                 lower_series, \n",
    "                 upper_series, \n",
    "                 color='k', alpha=.15)\n",
    "\n",
    "mtp.title(\"Final Forecast of Usage\")\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test = data_test.reset_index(drop=True)\n",
    "# Make predictions on the test data using the best ARIMA model\n",
    "y_pred = model_2.predict(len(data_test))\n",
    "\n",
    "# Calculate the metrics\n",
    "mae = mean_absolute_error(data_test['Close'], y_pred)\n",
    "mse = mean_squared_error(data_test['Close'], y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(data_test['Close'], y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n" , 

"test_data['Monthly beer production'].plot(figsize = (16,5), legend=True)" , 
"arima_pred.plot(legend = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
